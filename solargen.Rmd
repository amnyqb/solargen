---
title: "Solar Generation Forecasting using Machine Learning - Harvard Capstone Project"
author: "Amin Al Yaquob"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
options(repos = c(CRAN = "https://cran.rstudio.com/"))
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

This project aims to develop machine learning models for predicting solar power generation using weather data from two solar plants. The dataset consists of temperature, irradiation, and power generation values collected over time from sensors at the solar plants.

The primary objective is to accurately predict the Direct Current (DC) power generated by these plants. We will use different machine learning models, including Random Forest and XGBoost, to train and test on one plant's data and assess the model's performance on the other plant. 

### Data Source and Summary

The dataset used in this analysis is available at [Kaggle Solar Data](https://github.com/amnyqb/solar_ml/blob/main/kaggle_solardata.zip). It contains four files:
- Plant 1 Generation Data
- Plant 1 Weather Data
- Plant 2 Generation Data
- Plant 2 Weather Data

Each file includes detailed information on DC power output, temperature (ambient and module), and solar irradiation, collected over several months. In this analysis, we will focus on using the Plant 2 data for training and prediction. Below is a brief summary of the data:

- **Generation Data**: Includes features such as DC Power, AC Power, and Yield (total and daily).
- **Weather Data**: Contains features such as ambient temperature, module temperature, and solar irradiation.

---

# Approach

We will follow a structured approach to build the predictive models:

1. **Data Cleaning and Feature Engineering**: Prepare the data by converting date columns to appropriate formats and creating useful features such as `hour`, `day_of_week`, and `is_weekend`.
2. **Exploratory Data Analysis (EDA)**: Visualize the data to gain insights into the relationships between variables such as temperature, irradiation, and DC power generation.
3. **Model Training**: Implement various machine learning models, including Random Forest and XGBoost, and optimize their parameters.
4. **Model Evaluation**: Compare the models using Root Mean Square Error (RMSE) and other performance metrics.
5. **Conclusion**: Present the final results and discuss potential areas for improvement and future work.

---

## Required Packages

In this analysis, several R packages are required to perform data manipulation, machine learning modeling, and visualization. The following packages will be used:

- `prophet`: For time series forecasting.
- `tensorflow`: To build neural network models like LSTM.
- `randomForest`: For implementing Random Forest models.
- `caret`: For machine learning model training and tuning.
- `lubridate`: To handle date-time features.
- `dplyr`: For data manipulation.
- `ggplot2`: For data visualization.
- `corrplot` and `ggcorrplot`: To create correlation plots.
- `rpart`: For decision tree models.

```{r libraries, echo=TRUE, message=FALSE, warning=FALSE}
# Function to install missing packages
install_if_missing <- function(package) {
  if (!require(package, character.only = TRUE)) {
    install.packages(package, dependencies = TRUE)
    library(package, character.only = TRUE)
  }
}

# List of required packages
required_packages <- c("prophet", "tensorflow", "randomForest", 
                       "caret", "lubridate", "dplyr", "ggplot2", 
                       "corrplot", "ggcorrplot", "rpart","kableExtra")

# Install missing packages
lapply(required_packages, install_if_missing)
```




# Loading the Data

In this step, we will load the dataset, check for missing values, and convert the `DATE_TIME` column to a proper datetime format.





```{r load-data, message=FALSE, warning=FALSE}
# Load required libraries
library(tidyverse)
library(lubridate)
library(caret)
library(randomForest)


# Required libraries for downloading and unzipping files
library(tidyverse)

# Set the URL of the zip file and the destination
url <- "https://github.com/amnyqb/solar_ml/blob/main/kaggle_solardata.zip?raw=true"
destfile <- "kaggle_solardata.zip"

# Check if the file already exists, if not, download it
if (!file.exists(destfile)) {
  download.file(url, destfile, mode = "wb")
}

# Unzip the file if it hasn't been unzipped
if (!dir.exists("kaggle_solardata")) {
  unzip(destfile, exdir = "kaggle_solardata")
}

# Load the CSV files into variables
plant1_gen <- read_csv("kaggle_solardata/Plant_1_Generation_Data.csv")
plant2_gen <- read_csv("kaggle_solardata/Plant_2_Generation_Data.csv")
plant1_weather <- read_csv("kaggle_solardata/Plant_1_Weather_Sensor_Data.csv")
plant2_weather <- read_csv("kaggle_solardata/Plant_2_Weather_Sensor_Data.csv")


# Check for missing values
cat("Missing values in Plant 2 Generation Data:\n")
print(sapply(plant2_gen, function(x) sum(is.na(x))))

cat("Missing values in Plant 2 Weather Data:\n")
print(sapply(plant2_weather, function(x) sum(is.na(x))))

# Merge generation and weather data
plant2_data <- merge(plant2_gen, plant2_weather, by = "DATE_TIME")

# Preview the merged data
head(plant2_data)
```

# Data Cleaning and Feature Engineering

Before starting the analysis, we need to process the `DATE_TIME` column and create new features that can help improve our models' predictive power. Specifically, we will extract the hour of the day, the day of the week, and whether the date falls on a weekend.

```{r data-cleaning, message=FALSE, warning=FALSE}
# Convert DATE_TIME to a proper datetime format and extract useful features
plant2_data <- plant2_data %>%
  mutate(DATE_TIME = as.POSIXct(DATE_TIME, format = "%Y-%m-%d %H:%M:%S"),
         hour = as.numeric(format(DATE_TIME, "%H")),
         day_of_week = as.numeric(format(DATE_TIME, "%u")),
         week_number = isoweek(DATE_TIME),
         month = as.numeric(format(DATE_TIME, "%m")),
         year = as.numeric(format(DATE_TIME, "%Y")),
         is_weekend = ifelse(day_of_week > 5, 1, 0))

# Summary after feature engineering
summary(plant2_data)
```


# Exploratory Data Analysis (EDA)

The following visualizations provide insights into the relationships between key features such as temperature, irradiation, and DC power generation. These insights will guide our model-building process.

```{r eda, echo=TRUE, message=FALSE, warning=FALSE}
# 1. Distribution of DC Power
ggplot(plant2_data, aes(x = DC_POWER)) + 
  geom_histogram(binwidth = 100, fill = "blue", color = "grey") +
  ggtitle("Distribution of DC Power Generation") +
  xlab("DC Power (kW)") + ylab("Frequency")

# 2. DC Power vs Ambient Temperature
ggplot(plant2_data, aes(x = AMBIENT_TEMPERATURE, y = DC_POWER)) + 
  geom_point(alpha = 0.5) + 
  ggtitle("DC Power vs Ambient Temperature") + 
  xlab("Ambient Temperature (°C)") + ylab("DC Power (kW)")

# 3. DC Power vs Irradiation
ggplot(plant2_data, aes(x = IRRADIATION, y = DC_POWER)) + 
  geom_point(alpha = 0.5) + 
  ggtitle("DC Power vs Irradiation") + 
  xlab("Irradiation") + ylab("DC Power (kW)")

# 4. Correlation heatmap
cor_matrix <- cor(plant2_data %>% select(DC_POWER, AMBIENT_TEMPERATURE, MODULE_TEMPERATURE, IRRADIATION))
ggcorrplot(cor_matrix, method = "circle", lab = TRUE, title = "Correlation Heatmap")

# 5. DC Power by Hour of Day
ggplot(plant2_data, aes(x = hour, y = DC_POWER)) + 
  geom_boxplot() + 
  ggtitle("DC Power Distribution by Hour of Day") + 
  xlab("Hour of Day") + ylab("DC Power (kW)")

```


# Random Forest Model

We will begin by splitting the dataset into training and testing sets, then train a Random Forest model on the features `AMBIENT_TEMPERATURE`, `MODULE_TEMPERATURE`, `IRRADIATION`, `hour`, and `day_of_week`. Finally, we will evaluate the model performance using Root Mean Square Error (RMSE).

```{r random-forest, echo=TRUE, message=FALSE, warning=FALSE}
# Step 1: Split the data into training and testing sets
set.seed(123)
train_index <- createDataPartition(plant2_data$DC_POWER, p = 0.8, list = FALSE)
train_data <- plant2_data[train_index, ]
test_data <- plant2_data[-train_index, ]

# Step 2: Train Random Forest model
rf_model <- randomForest(DC_POWER ~ AMBIENT_TEMPERATURE + MODULE_TEMPERATURE + IRRADIATION + hour + day_of_week, 
                         data = train_data, 
                         ntree = 100)

# Step 3: Predict on the test set
rf_pred <- predict(rf_model, test_data)

# Step 4: Calculate RMSE for Random Forest
rf_rmse <- RMSE(rf_pred, test_data$DC_POWER)
cat("Random Forest RMSE: ", rf_rmse, "\n")

# Output variable importance
importance(rf_model)
```

# XGBoost Model

XGBoost is known for its scalability and performance, making it suitable for predicting solar power generation. In this section, we will train an XGBoost model and tune its hyperparameters to optimize its performance.

```{r xgboost, echo=TRUE, message=FALSE, warning=FALSE}
# Load required package for XGBoost
library(xgboost)

# Step 1: Prepare data for XGBoost (convert to matrix format)
train_matrix <- as.matrix(train_data[, c("AMBIENT_TEMPERATURE", "MODULE_TEMPERATURE", "IRRADIATION", "hour", "day_of_week")])
test_matrix <- as.matrix(test_data[, c("AMBIENT_TEMPERATURE", "MODULE_TEMPERATURE", "IRRADIATION", "hour", "day_of_week")])
train_label <- train_data$DC_POWER
test_label <- test_data$DC_POWER

# Step 2: Train XGBoost model
xgb_model <- xgboost(data = train_matrix, label = train_label, max_depth = 6, eta = 0.3, nrounds = 100, objective = "reg:squarederror", verbose = 0)

# Step 3: Predict on the test set
xgb_pred <- predict(xgb_model, test_matrix)

# Step 4: Calculate RMSE for XGBoost
xgb_rmse <- RMSE(xgb_pred, test_label)
cat("XGBoost RMSE: ", xgb_rmse, "\n")

# Output feature importance
xgb.importance(model = xgb_model)
```


# Hyperparameter Tuning

To ensure optimal performance, hyperparameters will be tuned using cross-validation. For Random Forest, we will tune `ntree`, and for XGBoost, we will tune `eta`, `max_depth`, and `nrounds`.

```{r hyperparameter-tuning, echo=TRUE, message=FALSE, warning=FALSE}
# Random Forest hyperparameter tuning
tuned_rf <- randomForest(DC_POWER ~ AMBIENT_TEMPERATURE + MODULE_TEMPERATURE + IRRADIATION + hour + day_of_week, 
                         data = train_data, 
                         ntree = 500)

# Predict and calculate RMSE
rf_tuned_pred <- predict(tuned_rf, test_data)
rf_tuned_rmse <- RMSE(rf_tuned_pred, test_data$DC_POWER)
cat("Tuned Random Forest RMSE: ", rf_tuned_rmse, "\n")

# XGBoost hyperparameter tuning
params <- list(max_depth = 6, eta = 0.1, objective = "reg:squarederror")
xgb_tuned_model <- xgboost(data = train_matrix, label = train_label, params = params, nrounds = 200, verbose = 0)

# Predict and calculate RMSE
xgb_tuned_pred <- predict(xgb_tuned_model, test_matrix)
xgb_tuned_rmse <- RMSE(xgb_tuned_pred, test_label)
cat("Tuned XGBoost RMSE: ", xgb_tuned_rmse, "\n")
```

# Model Evaluation and Results

The performance of each model is evaluated using the RMSE. In addition, we will create visualizations to compare the predicted vs actual values of the test dataset for better interpretation.


```{r model-evaluation, echo=TRUE, message=FALSE, warning=FALSE}
# Plot Predicted vs Actual values for Random Forest
library(knitr)  # For kable function to display tables
library(kableExtra)  # Optional for fancier tables

# Plot Predicted vs Actual values for Random Forest
ggplot(test_data, aes(x = rf_pred, y = DC_POWER)) + 
  geom_point(alpha = 0.5, color = "darkgreen") + 
  geom_abline(color = "red") + 
  ggtitle("Random Forest: Predicted vs Actual DC Power") + 
  xlab("Predicted DC Power") + 
  ylab("Actual DC Power")

# Plot Predicted vs Actual values for XGBoost
ggplot(test_data, aes(x = xgb_pred, y = DC_POWER)) + 
  geom_point(alpha = 0.5, color = "darkblue") + 
  geom_abline(color = "blue") + 
  ggtitle("XGBoost: Predicted vs Actual DC Power") + 
  xlab("Predicted DC Power") + 
  ylab("Actual DC Power")

# Create a results table
results <- data.frame(
  Model = c("Random Forest", "XGBoost", "Tuned Random Forest", "Tuned XGBoost"),
  RMSE = c(rf_rmse, xgb_rmse, rf_tuned_rmse, xgb_tuned_rmse)
)

# Display the table using knitr::kable()
kable(results, col.names = c("Model", "Root Mean Square Error (RMSE)"), 
      caption = "Model Performance Comparison") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = F)
```

# Forecast Accuracy Visualization for XGBoost Model

Visualizing Forecast Accuracy for Representative Days

In this section, we aim to provide a more granular view of the forecast accuracy of our XGBoost model by focusing on a set of representative days. While previous plots may have shown an overall trend, they could lack clarity due to the high resolution of continuous data points over an extended period. To address this, we present a 3x4 grid of charts, each showing DC power generation for a single representative day.

## Why Use Representative Days?

Selecting representative days allows us to zoom in on specific periods and closely inspect how well the model performs during typical and varying conditions. By isolating individual days, we can observe the variations in predicted versus actual power generation and highlight the model’s strengths or areas for improvement across different conditions.

## Filtering for Daytime Hours

Solar power generation naturally occurs only during the daytime, so including nighttime hours in our visualization would introduce unnecessary noise (since the DC power generation is zero during the night). For this reason, we have filtered the data to display only daytime hours (6 AM to 6 PM), focusing the analysis on the hours that contribute to meaningful DC power production.

## 3x4 Grid of Forecasts vs Actuals

To ensure clarity, we have selected 12 representative days from the test dataset, displayed in a 3x4 grid. Each chart within this grid plots:

	•	The actual DC power generation (solid blue line) recorded for that day.
	•	The predicted DC power generated by the XGBoost model (dashed red line).

By plotting the predicted vs actual power generation for each representative day, we gain insights into how well the model captures daily fluctuations in solar power generation. This approach enables a focused evaluation of how accurately the model performs across different days and time periods.

```{r}

# Load required libraries
library(tidyverse)
library(xgboost)
library(lubridate)
library(gridExtra)

# Step 1: Load and process data
# Assuming 'plant2_data' is already loaded in your environment
# Ensure DATE_TIME is in proper format
plant2_data <- plant2_data %>%
  mutate(DATE_TIME = as.POSIXct(DATE_TIME, format = "%Y-%m-%d %H:%M:%S"))

# Step 2: Prepare train and test data
set.seed(123)
train_index <- createDataPartition(plant2_data$DC_POWER, p = 0.8, list = FALSE)
train_data <- plant2_data[train_index, ]
test_data <- plant2_data[-train_index, ]

# Step 3: Prepare data for XGBoost (convert to matrix format)
train_matrix <- as.matrix(train_data[, c("AMBIENT_TEMPERATURE", "MODULE_TEMPERATURE", "IRRADIATION", "hour", "day_of_week")])
test_matrix <- as.matrix(test_data[, c("AMBIENT_TEMPERATURE", "MODULE_TEMPERATURE", "IRRADIATION", "hour", "day_of_week")])
train_label <- train_data$DC_POWER
test_label <- test_data$DC_POWER

# Step 4: Train XGBoost model
xgb_model <- xgboost(data = train_matrix, label = train_label, max_depth = 6, eta = 0.3, nrounds = 100, objective = "reg:squarederror", verbose = 0)

# Step 5: Predict on the test set
xgb_pred <- predict(xgb_model, test_matrix)

# Step 6: Add predictions to test_data
test_data$xgb_pred <- xgb_pred

# Step 7: Select 12 representative days
set.seed(123)
representative_days <- sample(unique(as.Date(test_data$DATE_TIME)), 12)

# Step 8: Filter daytime hours (assuming daytime is between 6 AM to 6 PM)
test_data_daytime <- test_data %>%
  filter(hour(DATE_TIME) >= 6 & hour(DATE_TIME) <= 18)

# Step 9: Create 12 individual plots for each representative day
plots <- list()

for (day in representative_days) {
  day_data <- test_data_daytime %>% filter(as.Date(DATE_TIME) == day)
  
  p <- ggplot(day_data, aes(x = DATE_TIME)) +
    geom_line(aes(y = DC_POWER, color = "Actual"), size = 0.5) +
    geom_line(aes(y = xgb_pred, color = "Predicted"), linetype = "dashed", size = 0.5) +
    labs(title = paste("Forecast vs Actual for", day), x = "Time", y = "DC Power") +
    scale_color_manual(values = c("Actual" = "blue", "Predicted" = "red")) +
    theme_minimal(base_size = 8) +
    theme(legend.position = "none", plot.title = element_text(size = 10))
  
  plots[[length(plots) + 1]] <- p
}

# Step 10: Arrange all 12 plots in a 3x4 grid
grid.arrange(grobs = plots, ncol = 3, top = "XGBoost Forecast vs Actual for 12 Representative Days (Daytime Hours Only)")

```









# Conclusion

In this study, we used machine learning models, including Random Forest and XGBoost, to predict the DC power output of a solar plant based on weather conditions. The models were evaluated using RMSE, and hyperparameter tuning was performed to optimize their performance. Our results show that both models provided good predictions, with XGBoost slightly outperforming Random Forest after hyperparameter tuning.

Future work could involve adding more advanced models like LSTM or Prophet to capture temporal dependencies more effectively, as well as incorporating additional data sources to improve the model's accuracy further.

---

# References
1. Solar Plant Data Source: [Kaggle Solar Data](https://github.com/amnyqb/solar_ml/blob/main/kaggle_solardata.zip)
2. Documentation for [Random Forest](https://www.rdocumentation.org/packages/randomForest/versions/4.6-14/topics/randomForest)
3. Documentation for [XGBoost](https://xgboost.readthedocs.io/en/stable/)

---





